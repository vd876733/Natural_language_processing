{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaLOaDNmTMdSahbh9SpK3O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vd876733/Natural_language_processing/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX1VH9yMCnDh",
        "outputId": "0248d967-3ed7-447e-f39a-9cc19c8a7000"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nT82BhMCozY",
        "outputId": "4c93a27e-9418-47cd-c41c-50fd638ad8b2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"nlp_text.txt\", \"r\") as file:\n",
        "    text = file.read()\n"
      ],
      "metadata": {
        "id": "2VAFXnuTCo1l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercase\n",
        "text = text.lower()\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Convert to list of sentences (required by Word2Vec)\n",
        "sentences = [tokens]\n",
        "\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxci5PGCo36",
        "outputId": "f30efa28-a627-4740-b62b-77f83f962f87"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.', 'it', 'allows', 'computers', 'to', 'understand', 'human', 'language', '.', 'text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'nlp', '.', 'tokenization', 'splits', 'text', 'into', 'words', '.', 'stopwords', 'are', 'common', 'words', 'that', 'are', 'removed', '.', 'stemming', 'reduces', 'words', 'to', 'their', 'root', '.', 'lemmatization', 'converts', 'words', 'to', 'meaningful', 'base', 'forms', '.', 'nlp', 'is', 'widely', 'used', 'in', 'chatbots', '.', 'search', 'engines', 'also', 'use', 'nlp', 'techniques', '.', 'machine', 'learning', 'improves', 'nlp', 'systems', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=100,\n",
        "    window=2,\n",
        "    sg=1,          # sg=1 → Skip-Gram\n",
        "    min_count=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "MOPLT4rhCo6Q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = model.wv['language']\n",
        "print(vector)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q42fm5MPCo8v",
        "outputId": "2857c343-2941-4778-be46-3d716d5cbd32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-9.5927063e-03  8.9482795e-03  4.1229748e-03  9.2436392e-03\n",
            "  6.6159894e-03  2.8720715e-03  9.8071294e-03 -4.3916656e-03\n",
            " -6.8246359e-03  4.1789939e-03  3.7365695e-03 -5.6942222e-03\n",
            "  9.7095743e-03 -3.5124153e-03  9.5846951e-03  8.2720164e-04\n",
            " -6.2945499e-03 -1.9844116e-03 -7.3941615e-03 -2.9977625e-03\n",
            "  1.0860424e-03  9.4768191e-03  9.3992585e-03 -6.6158483e-03\n",
            "  3.4836722e-03  2.2801880e-03 -2.5304584e-03 -9.2266388e-03\n",
            "  1.0375602e-03 -8.1612729e-03  6.3579888e-03 -5.8027087e-03\n",
            "  5.5768294e-03  9.7837877e-03 -1.7679192e-04  4.5483126e-03\n",
            " -1.8165699e-03  7.3849577e-03  3.9301049e-03 -9.0385340e-03\n",
            " -2.3928252e-03  3.6546721e-03 -1.0944577e-04 -1.1811114e-03\n",
            " -1.0652629e-03 -1.6694983e-03  5.9460831e-04  4.1660685e-03\n",
            " -4.2461571e-03 -3.8199185e-03 -5.1594150e-05  2.2840120e-04\n",
            " -2.0106246e-04 -4.8157442e-03  4.3794159e-03 -2.1261307e-03\n",
            "  2.1245738e-03  6.7324418e-04  5.9973905e-03 -6.8379203e-03\n",
            " -6.8272012e-03 -4.4909162e-03  9.4742747e-03 -1.5772586e-03\n",
            " -9.4388500e-03 -5.1946694e-04 -4.4559627e-03  6.0374443e-03\n",
            " -9.5949536e-03  2.8675094e-03 -9.2355451e-03  1.2135088e-03\n",
            "  6.0470449e-03  7.4442620e-03 -7.6110130e-03 -6.0592690e-03\n",
            " -6.8404265e-03 -7.9298196e-03 -9.5361732e-03 -2.1552870e-03\n",
            " -8.7558036e-04 -7.2303303e-03  6.7915022e-03  1.1311123e-03\n",
            "  5.8526336e-03  1.4555893e-03  8.4061438e-04 -7.3793619e-03\n",
            " -2.1760608e-03  4.3158433e-03 -5.0402428e-03  1.1305251e-03\n",
            "  2.8700528e-03 -1.5037073e-03  9.9560926e-03  8.3692446e-03\n",
            "  2.3880380e-03  7.1314299e-03  5.8858576e-03 -5.5864006e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = model.wv.most_similar('language')\n",
        "print(similar_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVBqquvjCo_T",
        "outputId": "6192e54e-e20d-4c42-e705-7577dda9d91d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('their', 0.2863123118877411), ('processing', 0.241204172372818), ('nlp', 0.19932447373867035), ('allows', 0.19047117233276367), ('of', 0.17497003078460693), ('artificial', 0.16729973256587982), ('natural', 0.12799929082393646), ('an', 0.10073989629745483), ('used', 0.09930845350027084), ('to', 0.07954800873994827)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.wv.index_to_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zF3Vp4_C8_E",
        "outputId": "d85fbe7b-60f2-4531-87d8-0fe03aa63d53"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.', 'words', 'nlp', 'to', 'is', 'are', 'in', 'text', 'language', 'systems', 'improves', 'learning', 'machine', 'techniques', 'use', 'also', 'engines', 'search', 'chatbots', 'used', 'widely', 'forms', 'base', 'meaningful', 'converts', 'lemmatization', 'root', 'their', 'reduces', 'stemming', 'removed', 'that', 'common', 'stopwords', 'into', 'splits', 'tokenization', 'step', 'important', 'an', 'preprocessing', 'human', 'understand', 'computers', 'allows', 'it', 'intelligence', 'artificial', 'of', 'field', 'fascinating', 'a', 'processing', 'natural']\n"
          ]
        }
      ]
    }
  ]
}