{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMuMN8d37w6Z",
        "outputId": "705d82b4-6fda-4180-e717-f7b9f0b411d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read text file\n",
        "with open(\"nlp_text.txt\", \"r\") as file:\n",
        "    text = file.read()\n",
        "\n",
        "print(\"Original Text:\\n\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfraKdjk8A3J",
        "outputId": "681f6527-98ba-4b77-9d77-0387fbb2e95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "\n",
            "Natural Language Processing is a fascinating field of Artificial Intelligence.\n",
            "It allows computers to understand human language.\n",
            "Text preprocessing is an important step in NLP.\n",
            "Tokenization splits text into words.\n",
            "Stopwords are common words that are removed.\n",
            "Stemming reduces words to their root.\n",
            "Lemmatization converts words to meaningful base forms.\n",
            "NLP is widely used in chatbots.\n",
            "Search engines also use NLP techniques.\n",
            "Machine learning improves NLP systems.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.lower()\n",
        "\n",
        "print(\"Lowercased Text:\\n\")\n",
        "print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72EZmk9w8B8c",
        "outputId": "280a8a0c-9e9d-49c9-c813-12aff2d2ccfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercased Text:\n",
            "\n",
            "natural language processing is a fascinating field of artificial intelligence.\n",
            "it allows computers to understand human language.\n",
            "text preprocessing is an important step in nlp.\n",
            "tokenization splits text into words.\n",
            "stopwords are common words that are removed.\n",
            "stemming reduces words to their root.\n",
            "lemmatization converts words to meaningful base forms.\n",
            "nlp is widely used in chatbots.\n",
            "search engines also use nlp techniques.\n",
            "machine learning improves nlp systems.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "print(\"Tokens:\\n\")\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlrsayN68CCf",
        "outputId": "bde74844-2442-442b-b484-763219e2548d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            "\n",
            "['natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.', 'it', 'allows', 'computers', 'to', 'understand', 'human', 'language', '.', 'text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'nlp', '.', 'tokenization', 'splits', 'text', 'into', 'words', '.', 'stopwords', 'are', 'common', 'words', 'that', 'are', 'removed', '.', 'stemming', 'reduces', 'words', 'to', 'their', 'root', '.', 'lemmatization', 'converts', 'words', 'to', 'meaningful', 'base', 'forms', '.', 'nlp', 'is', 'widely', 'used', 'in', 'chatbots', '.', 'search', 'engines', 'also', 'use', 'nlp', 'techniques', '.', 'machine', 'learning', 'improves', 'nlp', 'systems', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "\n",
        "print(\"After Stopword Removal:\\n\")\n",
        "print(filtered_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is8zb9DB8Re3",
        "outputId": "aa94c460-5bf0-4d8b-a802-33c5f00e0b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stopword Removal:\n",
            "\n",
            "['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'allows', 'computers', 'understand', 'human', 'language', 'text', 'preprocessing', 'important', 'step', 'nlp', 'tokenization', 'splits', 'text', 'words', 'stopwords', 'common', 'words', 'removed', 'stemming', 'reduces', 'words', 'root', 'lemmatization', 'converts', 'words', 'meaningful', 'base', 'forms', 'nlp', 'widely', 'used', 'chatbots', 'search', 'engines', 'also', 'use', 'nlp', 'techniques', 'machine', 'learning', 'improves', 'nlp', 'systems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"After Stemming:\\n\")\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O81GAsLS8UId",
        "outputId": "367687fa-f27b-4b91-f656-66780454f800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Stemming:\n",
            "\n",
            "['natur', 'languag', 'process', 'fascin', 'field', 'artifici', 'intellig', 'allow', 'comput', 'understand', 'human', 'languag', 'text', 'preprocess', 'import', 'step', 'nlp', 'token', 'split', 'text', 'word', 'stopword', 'common', 'word', 'remov', 'stem', 'reduc', 'word', 'root', 'lemmat', 'convert', 'word', 'meaning', 'base', 'form', 'nlp', 'wide', 'use', 'chatbot', 'search', 'engin', 'also', 'use', 'nlp', 'techniqu', 'machin', 'learn', 'improv', 'nlp', 'system']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "\n",
        "print(\"After Lemmatization:\\n\")\n",
        "print(lemmatized_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_5TThy38X61",
        "outputId": "cb6db2e2-a31f-483c-d8cc-f84a67fd3f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Lemmatization:\n",
            "\n",
            "['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'allows', 'computer', 'understand', 'human', 'language', 'text', 'preprocessing', 'important', 'step', 'nlp', 'tokenization', 'split', 'text', 'word', 'stopwords', 'common', 'word', 'removed', 'stemming', 'reduces', 'word', 'root', 'lemmatization', 'convert', 'word', 'meaningful', 'base', 'form', 'nlp', 'widely', 'used', 'chatbots', 'search', 'engine', 'also', 'use', 'nlp', 'technique', 'machine', 'learning', 'improves', 'nlp', 'system']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TOKENS:\\n\", tokens)\n",
        "print(\"\\nAFTER STOPWORDS REMOVAL:\\n\", filtered_tokens)\n",
        "print(\"\\nAFTER STEMMING:\\n\", stemmed_words)\n",
        "print(\"\\nAFTER LEMMATIZATION:\\n\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "GtEYggAi8dwr",
        "outputId": "66ce61e8-5400-4e4f-bc97-19d95cd98016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKENS:\n",
            " ['natural', 'language', 'processing', 'is', 'a', 'fascinating', 'field', 'of', 'artificial', 'intelligence', '.', 'it', 'allows', 'computers', 'to', 'understand', 'human', 'language', '.', 'text', 'preprocessing', 'is', 'an', 'important', 'step', 'in', 'nlp', '.', 'tokenization', 'splits', 'text', 'into', 'words', '.', 'stopwords', 'are', 'common', 'words', 'that', 'are', 'removed', '.', 'stemming', 'reduces', 'words', 'to', 'their', 'root', '.', 'lemmatization', 'converts', 'words', 'to', 'meaningful', 'base', 'forms', '.', 'nlp', 'is', 'widely', 'used', 'in', 'chatbots', '.', 'search', 'engines', 'also', 'use', 'nlp', 'techniques', '.', 'machine', 'learning', 'improves', 'nlp', 'systems', '.']\n",
            "\n",
            "AFTER STOPWORDS REMOVAL:\n",
            " ['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'allows', 'computers', 'understand', 'human', 'language', 'text', 'preprocessing', 'important', 'step', 'nlp', 'tokenization', 'splits', 'text', 'words', 'stopwords', 'common', 'words', 'removed', 'stemming', 'reduces', 'words', 'root', 'lemmatization', 'converts', 'words', 'meaningful', 'base', 'forms', 'nlp', 'widely', 'used', 'chatbots', 'search', 'engines', 'also', 'use', 'nlp', 'techniques', 'machine', 'learning', 'improves', 'nlp', 'systems']\n",
            "\n",
            "AFTER STEMMING:\n",
            " ['natur', 'languag', 'process', 'fascin', 'field', 'artifici', 'intellig', 'allow', 'comput', 'understand', 'human', 'languag', 'text', 'preprocess', 'import', 'step', 'nlp', 'token', 'split', 'text', 'word', 'stopword', 'common', 'word', 'remov', 'stem', 'reduc', 'word', 'root', 'lemmat', 'convert', 'word', 'meaning', 'base', 'form', 'nlp', 'wide', 'use', 'chatbot', 'search', 'engin', 'also', 'use', 'nlp', 'techniqu', 'machin', 'learn', 'improv', 'nlp', 'system']\n",
            "\n",
            "AFTER LEMMATIZATION:\n",
            " ['natural', 'language', 'processing', 'fascinating', 'field', 'artificial', 'intelligence', 'allows', 'computer', 'understand', 'human', 'language', 'text', 'preprocessing', 'important', 'step', 'nlp', 'tokenization', 'split', 'text', 'word', 'stopwords', 'common', 'word', 'removed', 'stemming', 'reduces', 'word', 'root', 'lemmatization', 'convert', 'word', 'meaningful', 'base', 'form', 'nlp', 'widely', 'used', 'chatbots', 'search', 'engine', 'also', 'use', 'nlp', 'technique', 'machine', 'learning', 'improves', 'nlp', 'system']\n"
          ]
        }
      ]
    }
  ]
}