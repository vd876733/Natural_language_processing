{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPn0sUdQTRynZwzLvQjmm50",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vd876733/Natural_language_processing/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANfN32PfA3rM",
        "outputId": "825d19a1-b215-405d-e973-c92b75f03fea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (4.67.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.3.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shCxbVRDA7vx",
        "outputId": "ece47e3a-65be-47b0-8fab-2046e6fb1b6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ],
      "metadata": {
        "id": "fF50GvRmA712"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"nlp_text.txt\", \"r\") as file:\n",
        "    text = file.read()\n"
      ],
      "metadata": {
        "id": "6akGyiXKBD2R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, \"→\", token.pos_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii18oz4aBD4z",
        "outputId": "8d88c029-649a-4dff-8871-6c2fbd5cf83d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Natural → PROPN\n",
            "Language → PROPN\n",
            "Processing → NOUN\n",
            "is → AUX\n",
            "a → DET\n",
            "fascinating → ADJ\n",
            "field → NOUN\n",
            "of → ADP\n",
            "Artificial → PROPN\n",
            "Intelligence → PROPN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "It → PRON\n",
            "allows → VERB\n",
            "computers → NOUN\n",
            "to → PART\n",
            "understand → VERB\n",
            "human → ADJ\n",
            "language → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Text → NOUN\n",
            "preprocessing → NOUN\n",
            "is → AUX\n",
            "an → DET\n",
            "important → ADJ\n",
            "step → NOUN\n",
            "in → ADP\n",
            "NLP → PROPN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Tokenization → NOUN\n",
            "splits → VERB\n",
            "text → NOUN\n",
            "into → ADP\n",
            "words → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Stopwords → NOUN\n",
            "are → AUX\n",
            "common → ADJ\n",
            "words → NOUN\n",
            "that → PRON\n",
            "are → AUX\n",
            "removed → VERB\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Stemming → NOUN\n",
            "reduces → VERB\n",
            "words → NOUN\n",
            "to → ADP\n",
            "their → PRON\n",
            "root → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Lemmatization → NOUN\n",
            "converts → VERB\n",
            "words → NOUN\n",
            "to → ADP\n",
            "meaningful → ADJ\n",
            "base → NOUN\n",
            "forms → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "NLP → PROPN\n",
            "is → AUX\n",
            "widely → ADV\n",
            "used → VERB\n",
            "in → ADP\n",
            "chatbots → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Search → NOUN\n",
            "engines → NOUN\n",
            "also → ADV\n",
            "use → VERB\n",
            "NLP → PROPN\n",
            "techniques → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n",
            "Machine → NOUN\n",
            "learning → NOUN\n",
            "improves → VERB\n",
            "NLP → PROPN\n",
            "systems → NOUN\n",
            ". → PUNCT\n",
            "\n",
            " → SPACE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(f\"Word: {token.text}\")\n",
        "    print(f\"POS Tag: {token.pos_}\")\n",
        "    print(f\"Detailed Tag: {token.tag_}\")\n",
        "    print(\"-----------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6GSPfRoBD7R",
        "outputId": "6ede374a-cf5e-4fbc-f86a-423729423b72"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: Natural\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: Language\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: Processing\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: is\n",
            "POS Tag: AUX\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: a\n",
            "POS Tag: DET\n",
            "Detailed Tag: DT\n",
            "-----------\n",
            "Word: fascinating\n",
            "POS Tag: ADJ\n",
            "Detailed Tag: JJ\n",
            "-----------\n",
            "Word: field\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: of\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: Artificial\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: Intelligence\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: It\n",
            "POS Tag: PRON\n",
            "Detailed Tag: PRP\n",
            "-----------\n",
            "Word: allows\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: computers\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: to\n",
            "POS Tag: PART\n",
            "Detailed Tag: TO\n",
            "-----------\n",
            "Word: understand\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VB\n",
            "-----------\n",
            "Word: human\n",
            "POS Tag: ADJ\n",
            "Detailed Tag: JJ\n",
            "-----------\n",
            "Word: language\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Text\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: preprocessing\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: is\n",
            "POS Tag: AUX\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: an\n",
            "POS Tag: DET\n",
            "Detailed Tag: DT\n",
            "-----------\n",
            "Word: important\n",
            "POS Tag: ADJ\n",
            "Detailed Tag: JJ\n",
            "-----------\n",
            "Word: step\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: in\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: NLP\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Tokenization\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: splits\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: text\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: into\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: words\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Stopwords\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: are\n",
            "POS Tag: AUX\n",
            "Detailed Tag: VBP\n",
            "-----------\n",
            "Word: common\n",
            "POS Tag: ADJ\n",
            "Detailed Tag: JJ\n",
            "-----------\n",
            "Word: words\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: that\n",
            "POS Tag: PRON\n",
            "Detailed Tag: WDT\n",
            "-----------\n",
            "Word: are\n",
            "POS Tag: AUX\n",
            "Detailed Tag: VBP\n",
            "-----------\n",
            "Word: removed\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBN\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Stemming\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: reduces\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: words\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: to\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: their\n",
            "POS Tag: PRON\n",
            "Detailed Tag: PRP$\n",
            "-----------\n",
            "Word: root\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Lemmatization\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: converts\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: words\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: to\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: meaningful\n",
            "POS Tag: ADJ\n",
            "Detailed Tag: JJ\n",
            "-----------\n",
            "Word: base\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: forms\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: NLP\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: is\n",
            "POS Tag: AUX\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: widely\n",
            "POS Tag: ADV\n",
            "Detailed Tag: RB\n",
            "-----------\n",
            "Word: used\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBN\n",
            "-----------\n",
            "Word: in\n",
            "POS Tag: ADP\n",
            "Detailed Tag: IN\n",
            "-----------\n",
            "Word: chatbots\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Search\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: engines\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: also\n",
            "POS Tag: ADV\n",
            "Detailed Tag: RB\n",
            "-----------\n",
            "Word: use\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBP\n",
            "-----------\n",
            "Word: NLP\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: techniques\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n",
            "Word: Machine\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: learning\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NN\n",
            "-----------\n",
            "Word: improves\n",
            "POS Tag: VERB\n",
            "Detailed Tag: VBZ\n",
            "-----------\n",
            "Word: NLP\n",
            "POS Tag: PROPN\n",
            "Detailed Tag: NNP\n",
            "-----------\n",
            "Word: systems\n",
            "POS Tag: NOUN\n",
            "Detailed Tag: NNS\n",
            "-----------\n",
            "Word: .\n",
            "POS Tag: PUNCT\n",
            "Detailed Tag: .\n",
            "-----------\n",
            "Word: \n",
            "\n",
            "POS Tag: SPACE\n",
            "Detailed Tag: _SP\n",
            "-----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tags = [(token.text, token.pos_) for token in doc]\n",
        "print(pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmgffg9BBZ2M",
        "outputId": "82177553-98f8-4758-825c-2d22dc4110a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Natural', 'PROPN'), ('Language', 'PROPN'), ('Processing', 'NOUN'), ('is', 'AUX'), ('a', 'DET'), ('fascinating', 'ADJ'), ('field', 'NOUN'), ('of', 'ADP'), ('Artificial', 'PROPN'), ('Intelligence', 'PROPN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('It', 'PRON'), ('allows', 'VERB'), ('computers', 'NOUN'), ('to', 'PART'), ('understand', 'VERB'), ('human', 'ADJ'), ('language', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Text', 'NOUN'), ('preprocessing', 'NOUN'), ('is', 'AUX'), ('an', 'DET'), ('important', 'ADJ'), ('step', 'NOUN'), ('in', 'ADP'), ('NLP', 'PROPN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Tokenization', 'NOUN'), ('splits', 'VERB'), ('text', 'NOUN'), ('into', 'ADP'), ('words', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Stopwords', 'NOUN'), ('are', 'AUX'), ('common', 'ADJ'), ('words', 'NOUN'), ('that', 'PRON'), ('are', 'AUX'), ('removed', 'VERB'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Stemming', 'NOUN'), ('reduces', 'VERB'), ('words', 'NOUN'), ('to', 'ADP'), ('their', 'PRON'), ('root', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Lemmatization', 'NOUN'), ('converts', 'VERB'), ('words', 'NOUN'), ('to', 'ADP'), ('meaningful', 'ADJ'), ('base', 'NOUN'), ('forms', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('NLP', 'PROPN'), ('is', 'AUX'), ('widely', 'ADV'), ('used', 'VERB'), ('in', 'ADP'), ('chatbots', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Search', 'NOUN'), ('engines', 'NOUN'), ('also', 'ADV'), ('use', 'VERB'), ('NLP', 'PROPN'), ('techniques', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE'), ('Machine', 'NOUN'), ('learning', 'NOUN'), ('improves', 'VERB'), ('NLP', 'PROPN'), ('systems', 'NOUN'), ('.', 'PUNCT'), ('\\n', 'SPACE')]\n"
          ]
        }
      ]
    }
  ]
}